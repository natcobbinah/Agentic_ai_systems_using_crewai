import asyncio 
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import AnyMessage, add_messages
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import tools_condition, ToolNode 
from typing import Annotated, List 
from typing_extensions import TypedDict 

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

from langchain_mcp_adapters.tools import load_mcp_tools 
import shlex

# MCP server launch config 
server_params = StdioServerParameters(
    command="python",
    args=["mcp_single_server_weather_app.py"]
)

async def list_prompts(session):
    """
    Fetches the list of available prompts from the connected server and prints them in a user-friendly format
    """
    try:
        prompt_response = await session.list_prompts()

        if not prompt_response or not prompt_response.prompts():
            print("\nNo prompts were found on the server")
            return 
        
        print("\nAvailable prompts and their arguments")
        print("--"(30))
        for p in prompt_response.prompts():
            print(f"Prompt: {p.name}")
            if p.arguments:
                arg_list = [f"<{arg.name}>" for arg in p.arguments]
                print(f" Arguments: {' '.join(arg_list)}")
            else:
                print("   Arguments: None")
        
        print("\nUsage: /prompt <prompt_name> \"arg1\" \"arg2\" ...")
        print("----"*30)
    except Exception as e:
        print(f"Error fetching prompots: {e}")

async def handle_prompt(session, command: str) -> str | None: 
    """
    Parses a user command to invoke a specific prompt from the server, 
    then returns the generated prompt ext
    """
    try:
        parts = shlex.split(command.strip())
        if len(parts) < 2: 
            print("\nUsage: /prompts <prompt_name> \"arg1\" \"arg2\"...")
            return None 
        
        prompt_name = parts[1]
        user_args = parts[2:]

        # get available prompts from the server to validate against
        prompt_def_response = await session.list_prompts()
        if not prompt_def_response or not prompt_def_response.prompts():
            print("\nError: Could not retrieve any prompots from the server.")
            return None 
        
        # find the specific prompt definition the user is asking for 
        prompt_def = next((p for p in prompt_def_response.prompts if p.name == prompt_name), None)

        if not prompt_def:
            print(f"\nError: Prompt '{prompt_name}' not found on the server")
            return None 
        
        # check if the number of user-provided arguments matches what the prompt expects
        if len(user_args) != len(prompt_def.arguments):
            expected_args = [arg.name for arg in prompt_def.arguments]
            print(f"\nError: Invalid number of arguments for prompt '{prompt_name}'")
            print(f"Expected {len(expected_args)} arguments: {', '.join(expected_args)}")
            return None 
        
        # build the argument dictionary
        arg_dict = {arg.name: val for arg, val in zip(prompt_def.arguments, user_args)}
        
        # fetch the prompt from the server using the validated name and arguments
        prompt_response = await session.get_prompt(prompt_name, arg_dict)

        # extract the text content from the response 
        prompt_text = prompt_response.messages[0].content.text 

        print("\n---Prompt loaded successfully. Preparing to execute.... ----")
        
        # return the fetched text to be used by the agent
        return prompt_text 
    except Exception as e:
        print(f"\nAn error occured during prompt invocation: {e}")
        return None

async def list_resources(session):
    """
    Fetches the list of available resources from the connected server
    and prints them in a user-friendly format
    """
    try:
        resource_response = await session.list_resources()

        if not resource_response or not resource_response.resources:
            print("\nNo resources found on the server")
            return 
        
        print("\nAvailable Resources:")
        print("---"*20)
        for r in resource_response.resources:
            # the URI is the unique identifier for the resource
            print(f" Resource URI: {r.uri}")
            
            # the description comes from the resource function's docstring
            if r.description:
                print(f"    Description: {r.description.strip()}")
        
        print("\nUsage: /resource <resource_uri>")
        print("---"*20)
    
    except Exception as e:
        print(f"Error fetching resources: {e}")

async def handle_resource(session, command: str) -> str | None:
    """
    Parses a user command to fetch a specific resource from the server 
    and returns its content as a single string
    """
    try:
        # The command format is "/resource <resource_uri>"
        parts = shlex.split(command.strip())
        if len(parts) != 2:
            print("\nUsage: /resource <resource_uri>")
            return None 
        
        resource_uri = parts[1]

        print(f"\n---- Fetching resource '{resource_uri}'... ---")

        # use the session's `read_resource` method with the provided uri
        response = await session.read_resource(resource_uri)

        if not response or not response.contents:
            print("Error: Resource not found or content is empty")
            return None 
        
        # extract text from all textcontent objects and join them
        # this handles cases where a resource might be split into multiple parts
        text_parts = [
            content.text for content in response.contents if hasattr(content, "text")
        ]

        if not text_parts:
            print("Error: Resource content is not in a readable text format")
            return None 
        
        resource_content = "\n".join(text_parts)

        print("--- Resource loaded successfully -----")
        return resource_content
    except Exception as e:
        print(f"\nAn error occured while fetching the resource: {e}")
        return None 

# langgraph state definition
class State(TypedDict):
    messages: Annotated[List[AnyMessage], add_messages]

async def create_graph(session):
    # load tools from MCP server
    tools = await load_mcp_tools(session)

    # LLM configuration
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        temperature=0,
        google_api_key="GOOGLE API KEY"
    )

    llm_with_tools = llm.bind_tools(tools)

    # prompt template with user/assistant chat only
    prompt_template = ChatPromptTemplate.from_messages([
        ("system", "you're a helpful assistant that uses tools to get the current weather for a location")
    ])

    chat_llm = prompt_template | llm_with_tools

    # define chat node
    def chat_node(state: State) -> State: 
        state["messages"] = chat_llm.invoke({
            "messages": state["messages"]
        })

    # build langgraph with tool routing
    graph = StateGraph(State)
    graph.add_node("chat_node", chat_node)
    graph.add_node("tool_node", ToolNode(tools=tools))
    graph.add_edge(START, "chat_node")
    graph.add_conditional_edges("chat_node", tools_condition, {
        "tools": "tool_node",
        "__end__": END 
    })
    graph.add_edge("tool_node", "chat_node")
    
    return graph.compile("tool_node", "chat_node")

# entry point
async def main():
    async with stdio_client(server_params) as (read,write):
        async with ClientSession(read,write) as session:
            await session.initialize()

            agent = await create_graph(session)

            print("Weather MCP agent is ready")

            # add instructions for the new prompt commands 
            print("Type a question, or use one of the following commands:")
            print(" /prompts                          - to list available prompts")
            print(" /prompt <prompt_name> \"args\"..  - to run a specific prompt")
            print(" /resources                        - to list available resources")
            print(" /resource <resource_uri> \"args\"..  - to load a resource for the agent")

            while True:
                # this variable will hold the final message to be sent to the agent
                message_to_agent = ""

                user_input = input("\nYou:").strip()
                if user_input.lower() in {"exit", "exit", "q"}:
                    break 

                # command handling logic 
                if user_input.lower() == "/prompts":
                    await list_prompts(session)
                    continue # command is done, loop back for next input
                
                elif user_input.lower() == "/resources":
                    await list_resources(session)
                    continue # command is done, loop back for next input

                elif user_input.startswith("/prompt"):
                    # the handle_prompt function now returns the prompt text or none 
                    prompt_text = await handle_prompt(session, user_input)
                    if prompt_text:
                        message_to_agent = prompt_text
                    else: 
                        # if prompt fetching failed, loop back for next input
                        continue
                
                elif user_input.startswith("/resource"):
                    # fetch the resource content using our new function
                    resource_content = await handle_resource(session, user_input)

                    if resource_content:
                        # ask the user what action to take on the loaded content
                        action_prompt = input("Resource loaded. What should  I do with this content? (Press Enter to just save to context)\n").strip()

                        # if user provides an action, combine it with the resource content
                        if action_prompt:
                            message_to_agent =f"""
                            CONTEXT from a loaded resource:
                            ------
                            {resource_content}
                            ------
                            TASK: {action_prompt}
                            """
                        # if user provides no action, create a default message to save the context
                        else:
                            print("No action specified. Adding resource content to conversation memory...")
                            message_to_agent=f"""
                            Please remember the following context for our conversation. Just acknowledge that you have received it.
                            ---
                            CONTEXT:
                            {resource_content}
                            ----
                            """
                    else:
                        # if resource loading failed, loop back for next input
                        continue
                
                else:
                    # for a normal chat message, the message is just the user's input
                    message_to_agent = user_input

                # final agent invocation
                # all paths (regular chat or successful prompt) now lead to this single block

                if message_to_agent:
                    try:
                        response = await agent.ainvoke(
                            {
                                "messages": [("user", message_to_agent)]
                            },
                            config = {
                                "configurable": {
                                    "thread_id": "weather-session"
                                }
                            }
                        )
                        print("AI:", response["messages"][-1].content)

                    except Exception as e:
                        print("Error:", e)

if __name__ == "__main__":
    asyncio.run(main())